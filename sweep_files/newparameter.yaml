program: "main.py"
method: "bayes"
parameters:
  epochs:
    distribution: constant
    value: 40 
  fold:
    distribution: constant
    value: 0
  loss:
    distribution: constant
    value: NP       
  learning_rate:
    distribution: uniform
    max: 0.1
    min: 0.00001   
  lambda_loss:
    distribution: constant
    value: 1
  batch_size:
    distribution: constant
    value: 1 
  is_SWEEP:
    distribution: constant
    value: 1
  is_reproducible:
    distribution: constant
    value: 1
  load_dataset_path:
    distribution: constant
    value: G:\MRC_still_10bits\IMVIA-DATASET-REDO-NUMPY-8BY8
  save_path:
    distribution: constant
    value: D:\imvia-data-storage\1-IMPORTANT-RUNS\HYPERPARAMETER-IMVIA
  database_name:
    distribution: constant
    value: MRL    
  dataset_percentage:
    distribution: constant
    value: 1 
  save_model_each_n_epochs:
    distribution: constant
    value: 0  
  optimizer:
    distribution: constant
    value: ADAM
  metric:
    distribution: constant
    value: hrmae
  network:
    distribution: constant
    value: UB8        
  window:
    distribution: constant
    value: 128 
  step_tr:
    distribution: constant
    value: 128     
  step_eval:
    distribution: constant
    value: 128      
  img_size:
    distribution: constant
    value: 8 
  channels:
    distribution: constant
    value: RGB
  predict_without_training:
    distribution: constant
    value: 0
  is_prediction:
    distribution: constant
    value: 0
  lambda:
    distribution: constant
    value: 1.32
  load_these_weights:
    distribution: constant
    value: G:\MRC_still_10bits\model_f-2_e009_UB8_AUG_PREVIOUSLY-USED.pth.tar
  
    
name: "UB8_lr_tuning"
description: "Tuning of learning rate in UB8, IMVIA"
metric:
  goal: "minimize"
  name: "val/hrmae"
  target: 0
project: "sweeps"  